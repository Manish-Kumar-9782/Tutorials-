{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputing Missing Values\n",
    "\n",
    "Imputing Missing Values by using the SimpleImputer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "Our aim to impute the missing values in our dataset to increase the performance of any estimator. In this section we will work on the `Life Expectancy` updated dataset which do not have any missing values so first we will load the data set then we will create fake `np.nan` values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Region</th>\n",
       "      <th>Year</th>\n",
       "      <th>Infant_deaths</th>\n",
       "      <th>Under_five_deaths</th>\n",
       "      <th>Adult_mortality</th>\n",
       "      <th>Alcohol_consumption</th>\n",
       "      <th>Hepatitis_B</th>\n",
       "      <th>Measles</th>\n",
       "      <th>BMI</th>\n",
       "      <th>...</th>\n",
       "      <th>Diphtheria</th>\n",
       "      <th>Incidents_HIV</th>\n",
       "      <th>GDP_per_capita</th>\n",
       "      <th>Population_mln</th>\n",
       "      <th>Thinness_ten_nineteen_years</th>\n",
       "      <th>Thinness_five_nine_years</th>\n",
       "      <th>Schooling</th>\n",
       "      <th>Economy_status_Developed</th>\n",
       "      <th>Economy_status_Developing</th>\n",
       "      <th>Life_expectancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Turkiye</td>\n",
       "      <td>Middle East</td>\n",
       "      <td>2015</td>\n",
       "      <td>11.1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>105.8240</td>\n",
       "      <td>1.32</td>\n",
       "      <td>97</td>\n",
       "      <td>65</td>\n",
       "      <td>27.8</td>\n",
       "      <td>...</td>\n",
       "      <td>97</td>\n",
       "      <td>0.08</td>\n",
       "      <td>11006</td>\n",
       "      <td>78.53</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.8</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>76.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>European Union</td>\n",
       "      <td>2015</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>57.9025</td>\n",
       "      <td>10.35</td>\n",
       "      <td>97</td>\n",
       "      <td>94</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>97</td>\n",
       "      <td>0.09</td>\n",
       "      <td>25742</td>\n",
       "      <td>46.44</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>9.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>82.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India</td>\n",
       "      <td>Asia</td>\n",
       "      <td>2007</td>\n",
       "      <td>51.5</td>\n",
       "      <td>67.9</td>\n",
       "      <td>201.0765</td>\n",
       "      <td>1.57</td>\n",
       "      <td>60</td>\n",
       "      <td>35</td>\n",
       "      <td>21.2</td>\n",
       "      <td>...</td>\n",
       "      <td>64</td>\n",
       "      <td>0.13</td>\n",
       "      <td>1076</td>\n",
       "      <td>1183.21</td>\n",
       "      <td>27.1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>65.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Guyana</td>\n",
       "      <td>South America</td>\n",
       "      <td>2006</td>\n",
       "      <td>32.8</td>\n",
       "      <td>40.5</td>\n",
       "      <td>222.1965</td>\n",
       "      <td>5.68</td>\n",
       "      <td>93</td>\n",
       "      <td>74</td>\n",
       "      <td>25.3</td>\n",
       "      <td>...</td>\n",
       "      <td>93</td>\n",
       "      <td>0.79</td>\n",
       "      <td>4146</td>\n",
       "      <td>0.75</td>\n",
       "      <td>5.7</td>\n",
       "      <td>5.5</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Israel</td>\n",
       "      <td>Middle East</td>\n",
       "      <td>2012</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.3</td>\n",
       "      <td>57.9510</td>\n",
       "      <td>2.89</td>\n",
       "      <td>97</td>\n",
       "      <td>89</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>94</td>\n",
       "      <td>0.08</td>\n",
       "      <td>33995</td>\n",
       "      <td>7.91</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>12.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>81.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country          Region  Year  Infant_deaths  Under_five_deaths  \\\n",
       "0  Turkiye     Middle East  2015           11.1               13.0   \n",
       "1    Spain  European Union  2015            2.7                3.3   \n",
       "2    India            Asia  2007           51.5               67.9   \n",
       "3   Guyana   South America  2006           32.8               40.5   \n",
       "4   Israel     Middle East  2012            3.4                4.3   \n",
       "\n",
       "   Adult_mortality  Alcohol_consumption  Hepatitis_B  Measles   BMI  ...  \\\n",
       "0         105.8240                 1.32           97       65  27.8  ...   \n",
       "1          57.9025                10.35           97       94  26.0  ...   \n",
       "2         201.0765                 1.57           60       35  21.2  ...   \n",
       "3         222.1965                 5.68           93       74  25.3  ...   \n",
       "4          57.9510                 2.89           97       89  27.0  ...   \n",
       "\n",
       "   Diphtheria  Incidents_HIV  GDP_per_capita  Population_mln  \\\n",
       "0          97           0.08           11006           78.53   \n",
       "1          97           0.09           25742           46.44   \n",
       "2          64           0.13            1076         1183.21   \n",
       "3          93           0.79            4146            0.75   \n",
       "4          94           0.08           33995            7.91   \n",
       "\n",
       "   Thinness_ten_nineteen_years  Thinness_five_nine_years  Schooling  \\\n",
       "0                          4.9                       4.8        7.8   \n",
       "1                          0.6                       0.5        9.7   \n",
       "2                         27.1                      28.0        5.0   \n",
       "3                          5.7                       5.5        7.9   \n",
       "4                          1.2                       1.1       12.8   \n",
       "\n",
       "   Economy_status_Developed  Economy_status_Developing  Life_expectancy  \n",
       "0                         0                          1             76.5  \n",
       "1                         1                          0             82.8  \n",
       "2                         0                          1             65.4  \n",
       "3                         0                          1             67.0  \n",
       "4                         1                          0             81.7  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the Life expectancy dataset.\n",
    "df = pd.read_csv(\"../datasets/Life-Expectancy-Data-Updated.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2864 entries, 0 to 2863\n",
      "Data columns (total 21 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   Country                      2864 non-null   object \n",
      " 1   Region                       2864 non-null   object \n",
      " 2   Year                         2864 non-null   int64  \n",
      " 3   Infant_deaths                2864 non-null   float64\n",
      " 4   Under_five_deaths            2864 non-null   float64\n",
      " 5   Adult_mortality              2864 non-null   float64\n",
      " 6   Alcohol_consumption          2864 non-null   float64\n",
      " 7   Hepatitis_B                  2864 non-null   int64  \n",
      " 8   Measles                      2864 non-null   int64  \n",
      " 9   BMI                          2864 non-null   float64\n",
      " 10  Polio                        2864 non-null   int64  \n",
      " 11  Diphtheria                   2864 non-null   int64  \n",
      " 12  Incidents_HIV                2864 non-null   float64\n",
      " 13  GDP_per_capita               2864 non-null   int64  \n",
      " 14  Population_mln               2864 non-null   float64\n",
      " 15  Thinness_ten_nineteen_years  2864 non-null   float64\n",
      " 16  Thinness_five_nine_years     2864 non-null   float64\n",
      " 17  Schooling                    2864 non-null   float64\n",
      " 18  Economy_status_Developed     2864 non-null   int64  \n",
      " 19  Economy_status_Developing    2864 non-null   int64  \n",
      " 20  Life_expectancy              2864 non-null   float64\n",
      "dtypes: float64(11), int64(8), object(2)\n",
      "memory usage: 470.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Summary:\n",
    "\n",
    "we have total `2864` entries and `21` columns, we don't found any non-value. \n",
    "\n",
    "* expect `country` and `year` columns all values are numerical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Infant_deaths</th>\n",
       "      <th>Under_five_deaths</th>\n",
       "      <th>Adult_mortality</th>\n",
       "      <th>Alcohol_consumption</th>\n",
       "      <th>Hepatitis_B</th>\n",
       "      <th>Measles</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Polio</th>\n",
       "      <th>Diphtheria</th>\n",
       "      <th>Incidents_HIV</th>\n",
       "      <th>GDP_per_capita</th>\n",
       "      <th>Population_mln</th>\n",
       "      <th>Thinness_ten_nineteen_years</th>\n",
       "      <th>Thinness_five_nine_years</th>\n",
       "      <th>Schooling</th>\n",
       "      <th>Economy_status_Developed</th>\n",
       "      <th>Economy_status_Developing</th>\n",
       "      <th>Life_expectancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2864.000000</td>\n",
       "      <td>2864.000000</td>\n",
       "      <td>2864.000000</td>\n",
       "      <td>2864.000000</td>\n",
       "      <td>2864.000000</td>\n",
       "      <td>2864.000000</td>\n",
       "      <td>2864.000000</td>\n",
       "      <td>2864.000000</td>\n",
       "      <td>2864.000000</td>\n",
       "      <td>2864.000000</td>\n",
       "      <td>2864.000000</td>\n",
       "      <td>2864.000000</td>\n",
       "      <td>2864.000000</td>\n",
       "      <td>2864.000000</td>\n",
       "      <td>2864.000000</td>\n",
       "      <td>2864.000000</td>\n",
       "      <td>2864.000000</td>\n",
       "      <td>2864.000000</td>\n",
       "      <td>2864.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2007.500000</td>\n",
       "      <td>30.363792</td>\n",
       "      <td>42.938268</td>\n",
       "      <td>192.251775</td>\n",
       "      <td>4.820882</td>\n",
       "      <td>84.292598</td>\n",
       "      <td>77.344972</td>\n",
       "      <td>25.032926</td>\n",
       "      <td>86.499651</td>\n",
       "      <td>86.271648</td>\n",
       "      <td>0.894288</td>\n",
       "      <td>11540.924930</td>\n",
       "      <td>36.675915</td>\n",
       "      <td>4.865852</td>\n",
       "      <td>4.899825</td>\n",
       "      <td>7.632123</td>\n",
       "      <td>0.206704</td>\n",
       "      <td>0.793296</td>\n",
       "      <td>68.856075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.610577</td>\n",
       "      <td>27.538117</td>\n",
       "      <td>44.569974</td>\n",
       "      <td>114.910281</td>\n",
       "      <td>3.981949</td>\n",
       "      <td>15.995511</td>\n",
       "      <td>18.659693</td>\n",
       "      <td>2.193905</td>\n",
       "      <td>15.080365</td>\n",
       "      <td>15.534225</td>\n",
       "      <td>2.381389</td>\n",
       "      <td>16934.788931</td>\n",
       "      <td>136.485867</td>\n",
       "      <td>4.438234</td>\n",
       "      <td>4.525217</td>\n",
       "      <td>3.171556</td>\n",
       "      <td>0.405012</td>\n",
       "      <td>0.405012</td>\n",
       "      <td>9.405608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>49.384000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>19.800000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2003.750000</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>9.675000</td>\n",
       "      <td>106.910250</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>23.200000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>1415.750000</td>\n",
       "      <td>2.097500</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>62.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2007.500000</td>\n",
       "      <td>19.600000</td>\n",
       "      <td>23.100000</td>\n",
       "      <td>163.841500</td>\n",
       "      <td>4.020000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>4217.000000</td>\n",
       "      <td>7.850000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>7.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>71.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2011.250000</td>\n",
       "      <td>47.350000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>246.791375</td>\n",
       "      <td>7.777500</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>26.400000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>12557.000000</td>\n",
       "      <td>23.687500</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>7.300000</td>\n",
       "      <td>10.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>75.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2015.000000</td>\n",
       "      <td>138.100000</td>\n",
       "      <td>224.900000</td>\n",
       "      <td>719.360500</td>\n",
       "      <td>17.870000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>32.100000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>21.680000</td>\n",
       "      <td>112418.000000</td>\n",
       "      <td>1379.860000</td>\n",
       "      <td>27.700000</td>\n",
       "      <td>28.600000</td>\n",
       "      <td>14.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>83.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Year  Infant_deaths  Under_five_deaths  Adult_mortality  \\\n",
       "count  2864.000000    2864.000000        2864.000000      2864.000000   \n",
       "mean   2007.500000      30.363792          42.938268       192.251775   \n",
       "std       4.610577      27.538117          44.569974       114.910281   \n",
       "min    2000.000000       1.800000           2.300000        49.384000   \n",
       "25%    2003.750000       8.100000           9.675000       106.910250   \n",
       "50%    2007.500000      19.600000          23.100000       163.841500   \n",
       "75%    2011.250000      47.350000          66.000000       246.791375   \n",
       "max    2015.000000     138.100000         224.900000       719.360500   \n",
       "\n",
       "       Alcohol_consumption  Hepatitis_B      Measles          BMI  \\\n",
       "count          2864.000000  2864.000000  2864.000000  2864.000000   \n",
       "mean              4.820882    84.292598    77.344972    25.032926   \n",
       "std               3.981949    15.995511    18.659693     2.193905   \n",
       "min               0.000000    12.000000    10.000000    19.800000   \n",
       "25%               1.200000    78.000000    64.000000    23.200000   \n",
       "50%               4.020000    89.000000    83.000000    25.500000   \n",
       "75%               7.777500    96.000000    93.000000    26.400000   \n",
       "max              17.870000    99.000000    99.000000    32.100000   \n",
       "\n",
       "             Polio   Diphtheria  Incidents_HIV  GDP_per_capita  \\\n",
       "count  2864.000000  2864.000000    2864.000000     2864.000000   \n",
       "mean     86.499651    86.271648       0.894288    11540.924930   \n",
       "std      15.080365    15.534225       2.381389    16934.788931   \n",
       "min       8.000000    16.000000       0.010000      148.000000   \n",
       "25%      81.000000    81.000000       0.080000     1415.750000   \n",
       "50%      93.000000    93.000000       0.150000     4217.000000   \n",
       "75%      97.000000    97.000000       0.460000    12557.000000   \n",
       "max      99.000000    99.000000      21.680000   112418.000000   \n",
       "\n",
       "       Population_mln  Thinness_ten_nineteen_years  Thinness_five_nine_years  \\\n",
       "count     2864.000000                  2864.000000               2864.000000   \n",
       "mean        36.675915                     4.865852                  4.899825   \n",
       "std        136.485867                     4.438234                  4.525217   \n",
       "min          0.080000                     0.100000                  0.100000   \n",
       "25%          2.097500                     1.600000                  1.600000   \n",
       "50%          7.850000                     3.300000                  3.400000   \n",
       "75%         23.687500                     7.200000                  7.300000   \n",
       "max       1379.860000                    27.700000                 28.600000   \n",
       "\n",
       "         Schooling  Economy_status_Developed  Economy_status_Developing  \\\n",
       "count  2864.000000               2864.000000                2864.000000   \n",
       "mean      7.632123                  0.206704                   0.793296   \n",
       "std       3.171556                  0.405012                   0.405012   \n",
       "min       1.100000                  0.000000                   0.000000   \n",
       "25%       5.100000                  0.000000                   1.000000   \n",
       "50%       7.800000                  0.000000                   1.000000   \n",
       "75%      10.300000                  0.000000                   1.000000   \n",
       "max      14.100000                  1.000000                   1.000000   \n",
       "\n",
       "       Life_expectancy  \n",
       "count      2864.000000  \n",
       "mean         68.856075  \n",
       "std           9.405608  \n",
       "min          39.400000  \n",
       "25%          62.700000  \n",
       "50%          71.400000  \n",
       "75%          75.400000  \n",
       "max          83.800000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values\n",
    "\n",
    "From basic info we already know that this dataset has no missing values values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country                        0\n",
       "Region                         0\n",
       "Year                           0\n",
       "Infant_deaths                  0\n",
       "Under_five_deaths              0\n",
       "Adult_mortality                0\n",
       "Alcohol_consumption            0\n",
       "Hepatitis_B                    0\n",
       "Measles                        0\n",
       "BMI                            0\n",
       "Polio                          0\n",
       "Diphtheria                     0\n",
       "Incidents_HIV                  0\n",
       "GDP_per_capita                 0\n",
       "Population_mln                 0\n",
       "Thinness_ten_nineteen_years    0\n",
       "Thinness_five_nine_years       0\n",
       "Schooling                      0\n",
       "Economy_status_Developed       0\n",
       "Economy_status_Developing      0\n",
       "Life_expectancy                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Missing Values randomly into over dataset.\n",
    "\n",
    "first we will do each step separately then we will combine them into a function.\n",
    "\n",
    "To create dataset with some `np.nan` values (randomly placed) we follow these following steps:\n",
    "\n",
    "1. first we will separate the dataset into the x_data and y_data\n",
    "2. we will choose the y_data as the `Life Expectancy` and `x_data` as the remaining variables.\n",
    "3. split data into the train and test.\n",
    "4. extract the number of entries and features.\n",
    "5. decide the how many missing values we will put.\n",
    "6. create a random binary sample with n_entries and put some `True` values equal to the missing values.\n",
    "7. Now we need one another sample of random number in b/w the `0` and `n_features`. \n",
    "8. Generate the missing sample.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we will separate the sample.\n",
    "y_data = df[\"Life_expectancy\"]\n",
    "\n",
    "# in our x_data we will remove the Country, Region Year and Life_Expectancy columns.\n",
    "x_data = df.drop(axis=1, columns=[\"Country\",\"Region\", \"Year\", \"Life_expectancy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2864, 17)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now testing our x_data shape\n",
    "x_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data into train and test dataset.\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will have train and test data set we need to only focus on the train dataset so from now we will  use the train dataset to create a new dataset with `np.nan` values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples:  2004\n",
      "Total number of featrues:  17\n"
     ]
    }
   ],
   "source": [
    "# to add missing values first we need to extract the number of entries and features from the xtrain dataset.\n",
    "n_sample, n_features = x_train.shape\n",
    "print(\"Total number of samples: \", n_sample)\n",
    "print(\"Total number of featrues: \", n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing value rate\n",
    "missing_rate = 0.30  # new dataset will have 30% missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of missing Values will be:  601\n"
     ]
    }
   ],
   "source": [
    "# Now compute the number of sample to have the missing values.\n",
    "n_missing_number = int(n_sample * missing_rate)\n",
    "print(\"Total number of missing Values will be: \", n_missing_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**sample of binary values for missing value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False ... False False False]\n"
     ]
    }
   ],
   "source": [
    "# Now creating a sample of binary values \n",
    "n_missing_sample = np.zeros(n_sample, dtype=bool)\n",
    "\n",
    "# now we will put some True we equal to the n_missing_number to our binary sample.\n",
    "n_missing_sample[:n_missing_number] = True\n",
    "\n",
    "# Now shuffle the data to distribute the True values to the whose sample equally.\n",
    "np.random.shuffle(n_missing_sample)\n",
    "\n",
    "# our new sample\n",
    "print(n_missing_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we also need one more random sample to select the feature to put the random value.\n",
    "n_missing_featrue = np.random.randint(0,n_features, n_missing_number) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14,  1,  4, 14,  2, 14, 11, 15,  3,  7, 15, 11, 10,  6, 11,  7,  8,\n",
       "        7, 13,  1,  2,  5, 16, 14, 14, 12,  3,  4,  3,  5, 13, 11,  4, 10,\n",
       "        4, 14,  8,  6, 15, 15, 11,  4,  8,  2, 16, 15,  4, 14,  3, 13, 13,\n",
       "        6,  9, 12,  5,  8, 14, 12, 11,  5, 15,  6,  5,  0, 13,  6, 14,  3,\n",
       "        8,  5,  4,  0, 14,  4,  3,  2, 13, 13, 15,  7,  5,  9,  1, 12,  9,\n",
       "        4, 14, 12,  3,  5,  4, 10,  8,  3, 16,  5, 15,  3, 10,  2,  4, 14,\n",
       "        9, 11, 14, 16,  2,  3, 13,  8,  9, 13, 13, 15,  4,  1, 13, 16,  1,\n",
       "        9, 14,  5, 16, 14, 10,  3,  9,  5, 14, 15,  4,  2, 14,  5, 10, 12,\n",
       "       13, 13,  3, 12, 16, 16,  6, 16, 14,  9, 13, 12, 11, 16,  7, 11,  1,\n",
       "       10,  3,  6, 12,  8,  5,  7,  0, 16, 14,  5, 14, 12, 15,  1, 14, 13,\n",
       "        8, 13,  2, 16, 11,  4,  9,  3,  0,  3, 12, 12,  8,  0,  4,  1,  9,\n",
       "       14,  0,  2,  0,  5, 11, 16, 13,  0,  7,  7,  3,  2, 16,  8,  8,  9,\n",
       "       16,  9, 16, 11, 13,  8,  3,  1, 13,  8, 14, 13,  4,  0, 15, 14,  1,\n",
       "        1, 12, 11,  5,  0,  5,  4,  7, 10,  8,  4, 14, 10, 15, 10,  2, 16,\n",
       "       13,  2, 12, 12,  4, 13, 14,  7, 15,  5,  8, 13,  5, 12,  4, 15,  4,\n",
       "       13, 15,  0,  9,  0, 16, 16, 12,  3, 12,  3,  4,  1, 12, 14,  4, 11,\n",
       "        8, 13, 13, 15, 16, 14,  6, 11, 15,  0,  2, 11,  6,  4,  4,  2,  7,\n",
       "        0, 10,  5,  5, 11,  3,  2, 10,  9,  6, 14,  2,  2,  8,  7, 10, 14,\n",
       "        6,  0, 14, 10,  3,  1,  7,  0, 11,  7,  2,  8,  3,  6,  3,  1,  3,\n",
       "       10,  9,  1, 10,  9,  2, 10, 15, 12,  5,  3,  7, 14, 13,  0,  5,  4,\n",
       "        3,  7, 10, 11,  7, 12,  1, 10,  6, 15,  2,  4, 10,  7,  0,  0,  4,\n",
       "       12, 15,  8,  0,  6,  6, 13,  4, 16,  1,  3, 10,  8,  5, 16, 15,  7,\n",
       "       15,  1,  8, 13, 15,  4,  2,  6, 10,  0, 12,  0,  8,  9, 13, 15, 12,\n",
       "       12,  8,  2,  2,  2, 13,  7,  7, 11, 13, 10,  9,  6,  5, 12, 15,  0,\n",
       "       16,  0, 14,  8,  1,  4,  0,  4,  4, 11,  9,  2, 13,  8, 11, 14,  8,\n",
       "        0,  2, 12,  3,  3, 14, 15, 13,  1,  2,  4, 12,  0, 15,  5, 12,  3,\n",
       "        9,  7,  7, 10,  1,  6, 16, 12,  6,  3,  9,  5,  9, 16, 10,  0, 14,\n",
       "       12,  9, 12,  4,  8, 16,  7,  5,  6,  9,  9,  9,  4,  3, 12, 13,  3,\n",
       "       10, 11,  3, 15,  2, 16,  0,  4,  9,  6,  6, 15,  8,  9, 10, 10,  5,\n",
       "        7,  6,  1,  5, 13,  0, 11,  2,  4, 13, 12,  3,  6, 14, 13,  9,  1,\n",
       "       13, 15,  7,  6,  0,  0,  8, 12,  8,  1,  6,  1,  9, 16,  4, 13,  8,\n",
       "        5,  5,  9, 13,  3,  7,  8, 12,  4,  0, 12, 13,  5,  7,  0,  5, 13,\n",
       "        7, 14, 14,  9, 15, 11,  1,  5,  0, 11,  6,  7,  9,  1, 13, 11, 10,\n",
       "        4, 10,  4,  2, 12,  2,  6, 14, 12, 15, 10, 10,  3,  2,  9,  0,  7,\n",
       "        0,  0,  4,  7,  0,  3,  5, 15, 13,  9,  8,  2,  6,  1,  3,  1,  9,\n",
       "        2,  4, 13,  8, 12, 10])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_missing_featrue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a copy to the data set\n",
    "x_train_copy = x_train.copy()\n",
    "y_train_copy = y_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_copy shape:  (2004, 17)\n",
      "n_missing_sample shape:  (2004,)\n",
      "n_missing_fetaure shape:  (601,)\n"
     ]
    }
   ],
   "source": [
    "# we need to inspect the shape of the x_train_copy and (n_missing_sample, n_missing_feature)\n",
    "print(\"x_train_copy shape: \", x_train_copy.shape)\n",
    "print(\"n_missing_sample shape: \", n_missing_sample.shape)\n",
    "print(\"n_missing_fetaure shape: \", n_missing_featrue.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our shape is matching with n_samples we are good to go.\n",
    "\n",
    "Now we will select all those sample who are marked for `np.nan` values and then form those we will select the `featrue` in which we want to put the `np.nan` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_x_train_data = x_train_copy.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_x_train_data[n_missing_sample, n_missing_featrue] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_data = pd.DataFrame(np_x_train_data, columns=x_train_copy.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Infant_deaths                  39\n",
       "Under_five_deaths              29\n",
       "Adult_mortality                34\n",
       "Alcohol_consumption            39\n",
       "Hepatitis_B                    44\n",
       "Measles                        36\n",
       "BMI                            29\n",
       "Polio                          32\n",
       "Diphtheria                     35\n",
       "Incidents_HIV                  36\n",
       "GDP_per_capita                 33\n",
       "Population_mln                 27\n",
       "Thinness_ten_nineteen_years    40\n",
       "Thinness_five_nine_years       46\n",
       "Schooling                      40\n",
       "Economy_status_Developed       34\n",
       "Economy_status_Developing      28\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_missing_value(x_data,y_data, missing_rate=.30):\n",
    "    \"\"\"Create artificial missing values in a dataset.\n",
    "\n",
    "    This function randomly selects n% of the samples and replaces one feature value with np.nan for each sample. \n",
    "    The output vector is not modified.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_data : array-like of shape (n_samples, n_features)\n",
    "        The input data matrix with all the features.\n",
    "    y_data : array-like of shape (n_samples,)\n",
    "        The output vector with the target values.\n",
    "    missing_rate: a float value to set the total number of missing values to add in the\n",
    "        dataset.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    x_missing : array-like of shape (n_samples, n_features)\n",
    "        The modified data matrix with missing values.\n",
    "    y_missing : array-like of shape (n_samples,)\n",
    "        The original output vector.\n",
    "    \n",
    "    \"\"\"\n",
    "    # extracting the numbr of samples and the features.\n",
    "    n_samples, n_features = x_data.shape\n",
    "    \n",
    "    # caluate the n_missing_number\n",
    "    n_missing_number = int(missing_rate * n_samples)\n",
    "    \n",
    "    # Now create a binary array equal to the n_samples size.\n",
    "    n_missing_samples = np.zeros(n_samples, dtype=bool)\n",
    "    \n",
    "    # Now put some True values on the samples equal to the n_missing_number\n",
    "    n_missing_samples[:n_missing_number] = True\n",
    "    \n",
    "    # now shuffle the n_missing_samples to distribute the missing value equally \n",
    "    # through out the dataset.\n",
    "    np.random.shuffle(n_missing_samples)\n",
    "    \n",
    "    # creating another n_feature_samples to select the featrue.\n",
    "    n_missing_features = np.random.randint(0, n_features, n_missing_number)\n",
    "    \n",
    "    # Now we will create a copy of the original data and transform the copy\n",
    "    x_missing = x_data.copy()\n",
    "    y_missing = y_data.copy()\n",
    "    \n",
    "    # putting some missing values.\n",
    "    x_missing[n_missing_samples, n_missing_features] = np.nan\n",
    "    \n",
    "    return x_missing, y_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding missing values.\n",
    "x_miss_data, y_miss_data = add_missing_value(x_train.to_numpy(), y_train.to_numpy(), 0.40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# again creating the dataframe with new values\n",
    "new_data = pd.DataFrame(x_miss_data, columns=x_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Infant_deaths                  52\n",
       "Under_five_deaths              49\n",
       "Adult_mortality                45\n",
       "Alcohol_consumption            36\n",
       "Hepatitis_B                    48\n",
       "Measles                        52\n",
       "BMI                            55\n",
       "Polio                          46\n",
       "Diphtheria                     48\n",
       "Incidents_HIV                  54\n",
       "GDP_per_capita                 39\n",
       "Population_mln                 44\n",
       "Thinness_ten_nineteen_years    64\n",
       "Thinness_five_nine_years       45\n",
       "Schooling                      35\n",
       "Economy_status_Developed       42\n",
       "Economy_status_Developing      47\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# displaying the total number of nan values in each feature\n",
    "new_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imputing the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a SimpleImputer to replace all the missing value with the mean\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "x_train_imputted =imputer.fit_transform(x_miss_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Infant_deaths                  0\n",
       "Under_five_deaths              0\n",
       "Adult_mortality                0\n",
       "Alcohol_consumption            0\n",
       "Hepatitis_B                    0\n",
       "Measles                        0\n",
       "BMI                            0\n",
       "Polio                          0\n",
       "Diphtheria                     0\n",
       "Incidents_HIV                  0\n",
       "GDP_per_capita                 0\n",
       "Population_mln                 0\n",
       "Thinness_ten_nineteen_years    0\n",
       "Thinness_five_nine_years       0\n",
       "Schooling                      0\n",
       "Economy_status_Developed       0\n",
       "Economy_status_Developing      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# again creating the dataframe with new values\n",
    "new_data = pd.DataFrame(x_train_imputted, columns=x_train.columns)\n",
    "new_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see that after imputing the data, we don't have any `np.nan` values in the train dataset. Now we will perform the `RandomForestRegressor` by using both the `Imputted` and `non-Imputted` dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression with Original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first create a LinearRegression instance\n",
    "regressor = RandomForestRegressor()\n",
    "\n",
    "# here x_train and y_train are the original data.\n",
    "regressor.fit(x_train, y_train)\n",
    "\n",
    "# now perform the cross validation on the regressor\n",
    "score = cross_val_score(regressor, x_train, y_train, scoring=\"neg_mean_squared_error\", cv=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score mean: -0.53\n",
      "score standard deviation:  0.04973003005274423\n"
     ]
    }
   ],
   "source": [
    "print(\"score mean: %.2f\"% (score.mean()))\n",
    "print(\"score standard deviation: \", score.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression with imputted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMSE : -0.91\n",
      "STD:  0.17758075798714867\n"
     ]
    }
   ],
   "source": [
    "# regression with imputted data\n",
    "regressor = RandomForestRegressor()\n",
    "score = cross_val_score(regressor, x_train_imputted, y_train, scoring=\"neg_mean_squared_error\", cv=5)\n",
    "print(f\"NMSE : {score.mean():.2f}\")\n",
    "print(\"STD: \", score.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred =  regressor.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction =  pd.DataFrame({\"y_pred\": y_pred, \"y_test\": y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction[\"error\"] = prediction[\"y_pred\"] - prediction[\"y_test\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3574989720930258"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
